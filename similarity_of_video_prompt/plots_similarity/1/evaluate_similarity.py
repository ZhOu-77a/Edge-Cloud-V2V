import os
import sys
import json
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# === é…ç½®åŒºåŸŸ ===
# åº”è¯¥æ”¹æˆå–å‰ä¿©å¸§å‡ºæ¥çœ‹çœ‹å³å¯
INPUT_VIDEO_DIR = os.path.join(parent_dir, "asset/batch_videos_6s_5")
PROMPT_CONFIG_FILE = os.path.join(parent_dir, "prompts_config.json")

OUTPUT_CSV = "source_target_gap.csv"
OUTPUT_PLOT_DIR = "plots_similarity"

# æ˜¾å¡è®¾ç½®
os.environ["CUDA_VISIBLE_DEVICES"] = "2" 
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

from stream_metrics import calc_clip_score
if not os.path.exists(OUTPUT_PLOT_DIR):
    os.makedirs(OUTPUT_PLOT_DIR)

def main():
    # 1. è¯»å– Prompts
    if not os.path.exists(PROMPT_CONFIG_FILE):
        print(f"âŒ Config file not found: {PROMPT_CONFIG_FILE}")
        return
    with open(PROMPT_CONFIG_FILE, 'r') as f:
        prompts_data = json.load(f)
    print(f"ğŸ“– Loaded {len(prompts_data)} prompts.")

    # 2. è¯»å– Videos
    if not os.path.exists(INPUT_VIDEO_DIR):
        print(f"âŒ Video dir not found: {INPUT_VIDEO_DIR}")
        return
    video_files = [f for f in os.listdir(INPUT_VIDEO_DIR) if f.endswith(('.mp4', '.avi', '.mov'))]
    video_files.sort()
    print(f"ğŸ“‚ Found {len(video_files)} videos.")

    results = []

    print("\nğŸš€ Starting Similarity Evaluation (Source Video vs Target Prompt)...")
    
    # 3. åŒé‡å¾ªç¯è®¡ç®—
    # è¿™é‡Œçš„ CLIP Score ä»£è¡¨ï¼šåŸè§†é¢‘ç”»é¢ ä¸ ç›®æ ‡æ–‡å­—æè¿° çš„ç›¸ä¼¼ç¨‹åº¦
    # åˆ†æ•°è¶Šä½ = è¯­ä¹‰å·®è·è¶Šå¤§ = ç†è®ºä¸Šç”Ÿæˆéš¾åº¦è¶Šå¤§
    for video_file in tqdm(video_files, desc="Videos"):
        video_path = os.path.join(INPUT_VIDEO_DIR, video_file)
        video_name = os.path.splitext(video_file)[0]
        
        for p_item in prompts_data:
            p_id = p_item['id']
            p_text = p_item['prompt']
            # p_diff = p_item['difficulty']
            
            # è®¡ç®— CLIP Score (åªå– text_score, å¿½ç•¥ consistency)
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ˜¯ç”¨ "åŸè§†é¢‘" å»æµ‹ "ç›®æ ‡Prompt"
            score, _ = calc_clip_score(video_path, p_text)
            
            results.append({
                "video": video_name,
                "prompt_id": p_id,
                "prompt_name": p_item['name'],
                # "difficulty_label": p_diff,
                "initial_clip_score": score
            })

    # 4. ä¿å­˜æ•°æ®
    df = pd.DataFrame(results)
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"\nğŸ’¾ Similarity scores saved to {OUTPUT_CSV}")

    # 5. å¯è§†åŒ–
    plot_analysis(df)

def plot_analysis(df):
    print("ğŸ“Š Generating plots...")
    
    # è®¾ç½®ç»˜å›¾é£æ ¼
    sns.set_theme(style="whitegrid")
    
    # --- å›¾ 1: çƒ­åŠ›å›¾ (Videos vs Prompts) ---
    # è¿™æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œé¢œè‰²è¶Šå†·(è“/ç´«)ä»£è¡¨ç›¸ä¼¼åº¦è¶Šä½(Gapè¶Šå¤§)ï¼Œé¢œè‰²è¶Šæš–(çº¢)ä»£è¡¨è¶Šç›¸ä¼¼
    plt.figure(figsize=(16, 10))
    pivot_table = df.pivot(index="prompt_name", columns="video", values="initial_clip_score")
    
    # ä½¿ç”¨ 'coolwarm' è‰²å›¾ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦åŒºåˆ† é«˜(ç›¸ä¼¼) å’Œ ä½(ä¸ç›¸ä¼¼)
    sns.heatmap(pivot_table, annot=True, fmt=".3f", cmap="RdYlBu_r", linewidths=.5)
    
    plt.title("Initial Semantic Similarity (Source Video vs Target Prompt)", fontsize=16)
    plt.xlabel("Source Video", fontsize=12)
    plt.ylabel("Target Prompt", fontsize=12)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_PLOT_DIR, "heatmap_similarity.png"))
    print("   ğŸ‘‰ Heatmap saved.")

    # # --- å›¾ 2: éš¾åº¦æ ‡ç­¾éªŒè¯ (Boxplot/Strip Plot) ---
    # # éªŒè¯æ‚¨çš„ "Easy/Medium/Hard/Extreme" æ ‡ç­¾æ˜¯å¦çœŸçš„å¯¹åº”äº† CLIP Score çš„ä¸‹é™
    # plt.figure(figsize=(12, 8))
    
    # # å®šä¹‰é¡ºåº
    # order = ["Easy", "Medium", "Hard", "Extreme"]
    
    # # ç®±çº¿å›¾å±•ç¤ºåˆ†å¸ƒ
    # sns.boxplot(x="difficulty_label", y="initial_clip_score", data=df, order=order, palette="Set2", linewidth=1.5)
    # # æ•£ç‚¹å›¾å±•ç¤ºå…·ä½“ç‚¹ (Jitter)
    # sns.stripplot(x="difficulty_label", y="initial_clip_score", data=df, order=order, color=".25", size=4, alpha=0.6)
    
    # plt.title("Verification of Difficulty Labels: Lower Score = Harder Task", fontsize=16)
    # plt.xlabel("Difficulty Label (Defined in JSON)", fontsize=12)
    # plt.ylabel("Initial CLIP Score (Source vs Prompt)", fontsize=12)
    
    # # æ·»åŠ å¹³å‡å€¼è¿çº¿ï¼Œçœ‹è¶‹åŠ¿
    # means = df.groupby("difficulty_label")["initial_clip_score"].mean().reindex(order)
    # plt.plot(range(len(order)), means, marker='o', color='red', linewidth=2, linestyle='--', label="Mean Trend")
    # plt.legend()
    
    # plt.tight_layout()
    # plt.savefig(os.path.join(OUTPUT_PLOT_DIR, "difficulty_validation.png"))
    # print("   ğŸ‘‰ Difficulty validation plot saved.")

    # # --- å›¾ 3: æ•£ç‚¹å›¾ (ID vs Score) ---
    # # ç›´è§‚å±•ç¤ºæ¯ä¸ª Prompt ID çš„å¹³å‡å¾—åˆ†ä¸ºå¤šå°‘
    # plt.figure(figsize=(14, 6))
    
    # avg_scores = df.groupby("prompt_id")["initial_clip_score"].mean().reset_index()
    # # æ˜ å°„é¢œè‰²
    # # ä¸ºäº†è®©ä¸åŒçš„éš¾åº¦æ˜¾ç¤ºä¸åŒé¢œè‰²ï¼Œæˆ‘ä»¬éœ€è¦ merge å›å»
    # diff_map = df[["prompt_id", "difficulty_label"]].drop_duplicates()
    # avg_scores = avg_scores.merge(diff_map, on="prompt_id")
    
    # sns.scatterplot(x="prompt_id", y="initial_clip_score", hue="difficulty_label", 
    #                 hue_order=order, data=avg_scores, s=100, palette="deep")
    
    # # ç”»çº¿è¿æ¥
    # plt.plot(avg_scores["prompt_id"], avg_scores["initial_clip_score"], color='gray', alpha=0.3)
    
    # plt.title("Average Initial Similarity per Prompt ID", fontsize=16)
    # plt.xlabel("Prompt ID", fontsize=12)
    # plt.ylabel("Average CLIP Score", fontsize=12)
    # plt.xticks(avg_scores["prompt_id"]) # ç¡®ä¿æ˜¾ç¤ºæ‰€æœ‰ ID
    # plt.grid(True, linestyle='--', alpha=0.6)
    
    # plt.tight_layout()
    # plt.savefig(os.path.join(OUTPUT_PLOT_DIR, "scatter_id_score.png"))
    # print("   ğŸ‘‰ Scatter plot saved.")

if __name__ == "__main__":
    main()